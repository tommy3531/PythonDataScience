# Overview
<p> This project is centered around data mining and parse json.  I am using data from propublica, NewsAPI, Opensecrets, Trade.gov, CKan.
    I make a request to each API create a model from the json response and then create a python object from the parsed Json Response.  I will use pandas and numpy to
    perform calculations on the data and persent the data to the use. </p>


# Third Party Libraries
1. NewsAPI - get news articles
2. JsonTraverseParser - parse json easier
3. scrapy - creating spiders
4. pyfolio - stock risk analysis
5. requests - REST Calls
6. gensim - NLP
7. scapy - NLP
8. NLTK- NPL toolkit
9. newspaper - extract articles and information from website


# Documentation
1. Data.gov - https://www.data.gov/developers/apis
3. NewsAPI - https://newsapi.org/docs
5. UnData - http://data.un.org/ws/
6. Opensecrets - https://www.opensecrets.org/api/admin/index.php?function=user_api_list
7. Scrapy - https://docs.scrapy.org/en/latest/
8. pyfolio - https://quantopian.github.io/pyfolio/
9. gensim - https://radimrehurek.com/gensim/tutorial.html
10. scapy - https://spacy.io/api/doc
11. newspaper - https://github.com/codelucas/newspaper


# Helpful Links
1. Open Data - https://project-open-data.cio.gov/


# Pyenv
<p> source ~/.bashrc set pycharm to use 3.5.2, checking setting in pycharm and make sure it is using pyenv version.
check local version of python, which python.  </p>
